{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### MACHINE LEARNING\n",
        "SE BASA FUNDAMENTALMENTE EN ALGORITMOS QUE SE UTILIZAN PARA MUCHAS APLICACIONES\n",
        "QUE AYUDAN A LAS MAQUINAS A APRENDER A PARTIR DE DATOS O EJEMPLOS\n",
        "\n",
        "HAY UNA ETAPA DE 'FEATURE EXTRACTION' PARA PREPARAR O PROCESAR LOS DATOS PARA\n",
        "QUE LOS ALGORITMOS PUEDAN TRABAJAR CON ELLOS\n",
        "\n",
        "PROGRAMACION TRADICIONAL             PROGRAM + DATA >>>>> OUTPUT\n",
        "MODELO MACHINE LEARNING        OUTPUT + DATA, DATA >>> OUTPUT     >>>> PROGRAM\n",
        "\n",
        "SUPERVISED VS UNSUPERVISED\n",
        "\n",
        "1.- SUPERVISED LEARNING. ALGORITMOS QUE APRENDEN DE MANERA SUPERVISADA.\n",
        "NECESITAN DATOS ETIQUETADOS. SI POR EJEMPLO ESTAMOS CLASIFICANDO IMAGENES\n",
        "NECESITAMOS EJEMPLOS DE LAS IMAGENES Y LA CLASE QUE TENEMOS QUE DARLE A CADA\n",
        "IMAGEN, ESTO LLEVA TIEMPO, ES DIFICIL, NECESITAS GENTE QUE HAGA ESO\n",
        "\n",
        "\n",
        "1.1 CLASSIFICATION. ASIGNAMOS UNA ETIQUETA A UNA CLASE\n",
        "1.1.1 SVM\n",
        "\n",
        "1.2 REGRESSION. DAR UN VALOR NUMERICO, PREDECIR EL PRECIO DE UNA CASA\n",
        "1.2.1 LINEAR REGRESSION\n",
        "1.2.2 DECISION TREES\n",
        "\n",
        "\n",
        "2.- UNSUPERVISED LEARNING. NO NECESITA DATASETS ETIQUETADOS, SOLO CON DATOS NO\n",
        "ETIQUETADOS DE FORMA NO SUPERVISADA ALGO APRENDEN TAMBIEN LOS ALGORITMOS\n",
        "\n",
        "2.1 CLUSTERING. AGRUPAR DATOS EN DIFERENTES GRUPOS QUE PUEDAN SERVIR PARA\n",
        "RESOLVER UNA TAREA\n",
        "2.1.1 K-MEANS\n",
        "2.1.2 HIERARCHICAL\n",
        "\n",
        "3.-PROBLEMAS DEL ML:\n",
        "3.1 CANTIDAD DE DATOS INSUFICIENTE,\n",
        "3.2 DATOS NO REPRESENTATIVOS,\n",
        "3.3 DATOS DE BAJA CALIDAD\n",
        "3.4 CARACTERISTICAS EN LOS DATOS IRRELEVANTES\n",
        "3.5 OVERFITTING O UNDERFITTING. EL MODELO NO ACABA DE AJUSTARSE BIEN A LOS DATOS\n",
        "\n",
        "\n",
        "EJEMPLO DE UN ALGORITMO DE MACHINE LEARNING MUY SENCILLO"
      ],
      "metadata": {
        "id": "iARYnM3GOy-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df=pd.read_csv('country_stats.csv')\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "q551uKPuT30C",
        "outputId": "fc5b6416-926a-48ea-b5ad-230761cf29e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-943566826708>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'country_stats.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'country_stats.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind= 'scatter', x='GDP per capita', y='Life satisfaction')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ufooZEUGUm2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#parece que se ve una tendencia que indica que cuanto mayor es el PIB de un pais\n",
        "#mas satisfecha esta la gente\n",
        "#vamos a desarrollar un modelo que en base a estos datos nos permita saber para\n",
        "#cualquier pais su nivel de satisfaccion, es una tarea de regresion\n",
        "#vamos a usar un algoritmo muy simple que se basa en una regresion lineal, es\n",
        "#una recta\n",
        "#y= m*x + b\n",
        "\n",
        "#y    variable que queremos predecir\n",
        "#m\n",
        "#x     PIB\n",
        "#b\n",
        "\n",
        "#tenemos que entrenar a este modelo para darle unos valores a los parametros\n",
        "#que son la m y la b, que se ajusten a la tendencia que vemos en la grafica\n",
        "\n",
        "#usamos la libreria de Scikit Learn"
      ],
      "metadata": {
        "id": "HOgsu4dUVzDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "import numpy as np\n",
        "\n",
        "lin1 = linear_model.LinearRegression()\n",
        "Xsample = np.c_[df[\"GDP per capita\"]]\n",
        "ysample = np.c_[df[\"Life satisfaction\"]]\n",
        "lin1.fit(Xsample, ysample)\n",
        "b, m= lin1.intercept_[0], lin1.coef_[0][0]\n",
        "b, m"
      ],
      "metadata": {
        "id": "zsnP5nHYXgNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3))\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "X=np.linspace(0, 60000, 1000)\n",
        "plt.plot(X, b + m*X, \"r\")\n",
        "plt.text(5000, 3.1, r\"$b = 4.85$\", fontsize=14, color=\"g\")\n",
        "plt.text(5000, 2.2, r\"$w = 4.91 \\times 10^{-5}$\", fontsize=14, color=\"b\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cZq8OuxdYRZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos a usar nuestro algoritmo para predecir el nivel de satisfaccion de\n",
        "#cualquier pais del que sepamos su PIB\n",
        "\n",
        "cyprus_gdp_per_capita = 22587\n",
        "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0][0]\n",
        "cyprus_predicted_life_satisfaction"
      ],
      "metadata": {
        "id": "lZ92OY_OYj5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(kind='scatter', x=\"GDP per capita\", y='Life satisfaction', figsize=(5,3), s=1)\n",
        "plt.xlabel(\"GDP per capita (USD)\")\n",
        "X=np.linspace(0, 60000, 1000)\n",
        "plt.plot(X, b + m*X, \"b\")\n",
        "plt.axis([0, 60000, 0, 10])\n",
        "plt.text(5000, 7.5, r\"$b = 4.85$\", fontsize=14, color=\"b\")\n",
        "plt.text(5000, 6.6, r\"$w = 4.91 \\times 10^{-5}$\", fontsize=14, color=\"b\")\n",
        "plt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita], [0, cyprus_predicted_life_satisfaction], \"r-.\")\n",
        "plt.text(25000, 5.0, r\"Prediction = 5.96\", fontsize=14, color=\"b\")\n",
        "plt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MHz8_8xGY_ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### POLYNOMIAL REGRESSION"
      ],
      "metadata": {
        "id": "FcwoFF0pGgkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Queremos predecir el precio de una casa basado en varias caracteristicas como\n",
        "#ubicacion, metros cuadrados de parcela, numero de habitaciones, piscina, etc\n",
        "\n",
        "#Ya vimos la formula tipica de regresion lineal\n",
        "# Y= Wo + W1X1 + W2X2 + W3X3....\n",
        "# Donde Y es el precio de la casa a predecir\n",
        "# X son las caracteristicas(habitaciones, metros cuadrados, etc)\n",
        "# W son los pesos(weights) o parametros del modelo\n",
        "\n",
        "# Una metrica comun sobre la calidad de nuestro modelo es el SME (squared mean\n",
        "# error), valores predichos menos el valor reales lo elevamos al cuadrado y los\n",
        "#sumamos para todas las muestras que tengamos, dividimos por el numero total de\n",
        "#muestras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 3 * X + np.random.randn(100, 1)\n",
        "\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([0, 2, -3, 10])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Y seria el precio de la casa\n",
        "#X1 seria la unica variable o caracteristica de la casa (metros cuadrados, por\n",
        "#ejemplo)"
      ],
      "metadata": {
        "id": "Q2sacM7UHz6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vamos a entrenar un modelo de regresion lineal con sklearn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg= LinearRegression()\n",
        "lin_reg.fit(X,y)\n",
        "lin_reg.intercept_, lin_reg.coef_\n",
        "\n",
        "#En el coef tenemos todos los pesos (w) que se multiplican por las\n",
        "#caracteristicas (X), en este caso solo hay el W1 porque solo hay una variable\n",
        "#o caracteristica (X1)\n",
        "#En el intercept tenemos el Wo o bias"
      ],
      "metadata": {
        "id": "5gQSRU3GMRev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#llamamos a la funcion predict con datos nuevos para sacar prediccione\n",
        "#en este caso vamos a sacar predicciones para los puntos 0 y 2\n",
        "\n",
        "X_new = np.array([[0], [2]])\n",
        "y_predict = lin_reg.predict(X_new)\n",
        "plt.plot(X_new, y_predict, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([0, 2, -3, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jkQR9-mgO40Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#la linea intenta ajustarse lo maximo posible a los datos e intenta minimizar\n",
        "#el SME"
      ],
      "metadata": {
        "id": "PXImiZyOPjqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#que sucede si los datos NO siguen una tendencia lineal tan sencilla como\n",
        "#la de arriba\n",
        "\n",
        "import numpy.random as rnd\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)\n",
        "\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3ybk9mmFP6Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "\n",
        "X_new = np.array([[-3], [3]])\n",
        "y_predict = lin_reg.predict(X_new)\n",
        "plt.plot(X_new, y_predict, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YYV1EEksRsb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#en SKLEARN podemos usar modelos de regresion polinomial para que se ajuste\n",
        "#mas a la realidad de estos nuevos datos, usariamos curvas en vez de rectas\n",
        "\n",
        "#lo que vamos a hacer es procesar nuestros datos para transformarlos en un\n",
        "#espacio de representacion con mas variables x1 x2 x3 etc. de forma que en\n",
        "#este nuevo espacio transformado nuestros datos sigan una tendencia lineal\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "X[0], X_poly[0]  #compara la primera fila de la matriz original X y la\n",
        "#primera fila de la matriz transformada\n",
        "\n",
        "#la funcion transform cambia una variable a dos variables como vemos abajo\n",
        "#estas dos variables representan lo mismo que la variable unica pero en\n",
        "#otro espacio\n"
      ],
      "metadata": {
        "id": "YxQ1T8RhQUyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#si ahora entrenamos el modelo usando los nuevos datos procesados veamos\n",
        "#que tenemos otro modelo que nos da mejores resultados\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y)\n",
        "lin_reg.intercept_, lin_reg.coef_"
      ],
      "metadata": {
        "id": "Lm0WDvTMTUwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
        "X_new_poly = poly_features.transform(X_new)\n",
        "y_new = lin_reg.predict(X_new_poly)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e_2yk_iqUDUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#como se yo el grado del polinomio?, con tantas variables que afectan al precio\n",
        "#de la casa, prueba un monton de valores y quedate con el que mejor funcione\n",
        "#hiperoptimizacion de parametroS\n",
        "#probaremos varios grados diferentes 1, 2, 40 o mas\n",
        "#para cada uno de ellos calculamos su metrica , su SME y veremos cual funciona\n",
        "#mejor\n",
        "#cuando usamos el grado 1 tenemos un problema de underfitting (poco ajustado)\n",
        "#cuando usamos el grado 40 tenemos un problema de overfitting (demasiado\n",
        "#ajustado)\n",
        "#Para evaluar estos modelos lo tenemos que hacer con datos nuevos, problamente\n",
        "#el modelo grado 2 nos de mejor resultados, pero si no evaluaramos con datos\n",
        "#nuevos el grado 40 nos daria mejores resultado (no GENERALIZA bien a los datos\n",
        "#nuevos)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "for style, width, degree in ((\"g-\", 1, 40), (\"b--\", 2, 2), (\"r-+\", 2, 1)):\n",
        "    polybig_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "    std_scaler = StandardScaler()\n",
        "    lin_reg = LinearRegression()\n",
        "    polynomial_regression = Pipeline([\n",
        "            (\"poly_features\", polybig_features),\n",
        "            (\"std_scaler\", std_scaler),\n",
        "            (\"lin_reg\", lin_reg),\n",
        "        ])\n",
        "    polynomial_regression.fit(X, y)\n",
        "    y_newbig = polynomial_regression.predict(X_new)\n",
        "    plt.plot(X_new, y_newbig, style, label=str(degree), linewidth=width)\n",
        "\n",
        "plt.plot(X, y, \"b.\", linewidth=3)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Lu4QDpl9UZNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "pln3agp4ciU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# La regresión logística en scikit-learn se considera un modelo de clasificación.\n",
        "# Aunque el término \"regresión\" está presente en su nombre, la regresión logística\n",
        "# se utiliza principalmente para problemas de clasificación binaria o multiclase.\n",
        "\n",
        "# La regresión logística estima la probabilidad de que una instancia pertenezca a\n",
        "# una clase específica utilizando una función logística o sigmoide.\n",
        "# A partir de esta probabilidad estimada, se toma una decisión de clasificación\n",
        "# asignando la instancia a la clase con la probabilidad más alta.\n",
        "\n",
        "# En el caso del dataset Iris en scikit-learn, la regresión logística se puede\n",
        "# utilizar para clasificar las flores en diferentes especies utilizando las\n",
        "# características disponibles en el conjunto de datos.\n",
        "\n",
        "# El dataset Iris contiene mediciones de características de tres especies de\n",
        "# flores: setosa, versicolor y virginica. Cada muestra del dataset tiene cuatro\n",
        "# características: longitud y ancho del sépalo, y longitud y ancho del pétalo.\n"
      ],
      "metadata": {
        "id": "9679Jx3_cmBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#cargamos el dataset Iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n"
      ],
      "metadata": {
        "id": "nCUWZRgydYvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "F3JOR7RadxUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos una instancia del modelo de regresion logistica y entrenarlo\n",
        "\n",
        "logreg=LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "O-cKmrHKd8QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#realizamos prediccion en el conjunto de prueba\n",
        "\n",
        "y_pred=logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "lqJVaOZ6eMXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluamos el rendimiento del modelo mediante alguna metrica como\n",
        "#por ejemplo la precision\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Precisión:\", accuracy)"
      ],
      "metadata": {
        "id": "DSDFTr8tecXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_confusion=confusion_matrix(y_test, y_pred)\n",
        "print(matriz_confusion)"
      ],
      "metadata": {
        "id": "7GYL-s5Ve99j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "lAxB2tK0fbru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K NEAREST NEIGHBORS"
      ],
      "metadata": {
        "id": "5p2MW---4C-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN es un algoritmo de aprendizaje supervisado usado tanto para problemas de\n",
        "#clasificacion cuando las etiquetas son categoricas como para problemas de\n",
        "#regresion cuando las etiquetas son numericas\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#cargar el conjunto  de datos de ejemplo de Iris\n",
        "\n",
        "iris=load_iris()\n",
        "X=iris.data    # caracteristicas\n",
        "y=iris.target   #etiquetas\n",
        "\n",
        "#Dividir el conjunto de datos en datos de entrenamiento y datos de prueba\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Crear una instancia del clasificador K-NN con K=3, los 3 vecinos mas cercanos\n",
        "knn=KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "#Entrenar el clasificador usando los datos de entrenamiento\n",
        "\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Realizar predicciones en los datos de prueba\n",
        "\n",
        "y_pred=knn.predict(X_test)\n",
        "\n",
        "#Calcular la precision de las predicciones\n",
        "accuracy=accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Precision:', accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pLFVFNz4QBU",
        "outputId": "5cac63e4-8080-41f2-826f-d4823ef4397d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8NI03uDoeDt"
      },
      "outputs": [],
      "source": [
        "# Classification\n",
        "# Identifying which category an object belongs to\n",
        "# Application: Spam detection. Is it a spam or not? Is it a good wine or not\n",
        "\n",
        "# Regression\n",
        "# Predicting an attribute associated with an object\n",
        "# Application: Stock prices prediction, weather forecasting\n",
        "\n",
        "# Clustering\n",
        "# Automatic grouping of similar objects into sets\n",
        "# Application: Customer segmentation if these customers like this maybe\n",
        "# they like that\n",
        "\n",
        "# Model selection\n",
        "# Comparing, validating and choosing parameters and models\n",
        "# Application: Improving model accuracy via parameter tuning\n",
        "\n",
        "# Dimensionality reduction\n",
        "# Reducing the number of random variables to consider\n",
        "# Application: To increase model efficiency\n",
        "\n",
        "# Pre-processing\n",
        "# Feature extraction and normalization\n",
        "# Application: Transforming input data such as text for use with machine\n",
        "# learning algorithms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Modelos más usados\n",
        "# Linear model\n",
        "# SVM classifier\n",
        "# Nearest neighbours KNN\n",
        "# Decision trees\n",
        "# Neural networks\n",
        "# Forest"
      ],
      "metadata": {
        "id": "Y-B0JQYyxB9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required packages.\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "#mejor para que no falle en el google colab"
      ],
      "metadata": {
        "id": "EMn1U2nCzZQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine=pd.read_csv('winequality-red.csv', sep=';')"
      ],
      "metadata": {
        "id": "3RpxpeGzK8Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head()"
      ],
      "metadata": {
        "id": "lsQ5yd4HLceC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.info()"
      ],
      "metadata": {
        "id": "A7Gsi18VLfPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.isnull().sum()"
      ],
      "metadata": {
        "id": "CSAsriQGLiRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Data\n",
        "bins= (2, 6.5, 8)\n",
        "group_names= ['bad', 'good']\n",
        "wine['quality']=pd.cut(wine['quality'], bins=bins, labels=group_names)\n",
        "wine['quality'].unique()"
      ],
      "metadata": {
        "id": "7vQ5U0ouLmAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now lets assign a labels to our quality variable\n",
        "label_quality = LabelEncoder()"
      ],
      "metadata": {
        "id": "OVsd7AhJLoxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine['quality'] = label_quality.fit_transform(wine['quality'])\n",
        "\n",
        "#Bad becomes 0 and good becomes 1"
      ],
      "metadata": {
        "id": "7Kj0xQc7Lr3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head(10)"
      ],
      "metadata": {
        "id": "mBpyV7PxLttN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine['quality'].value_counts()"
      ],
      "metadata": {
        "id": "6MawWeguLw4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(wine['quality'])"
      ],
      "metadata": {
        "id": "AgleK56HL1c3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now separate the dataset as response variable and feature variabes\n",
        "X = wine.drop('quality', axis = 1)\n",
        "y = wine['quality']"
      ],
      "metadata": {
        "id": "qfKaEt7dL5vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and Test splitting of data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "a7wImOUhL7_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying Standard scaling to get optimized result\n",
        "#La mayoria de los modelos necesitan scaling, los valores de nuestra base de\n",
        "#datos son muy grandes comparados con otros y eso puede hacer que el modelo\n",
        "#se concentre demasiado en los valores grandes\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.fit_transform(X_test)\n"
      ],
      "metadata": {
        "id": "fCQDVdYdL-t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora los valores estan menos dispersos y oscilan entre -2 y 4 mas o menos\n",
        "X_train[:10]"
      ],
      "metadata": {
        "id": "XSfeAIBHMCbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.- RANDOM FOREST CLASSIFIER"
      ],
      "metadata": {
        "id": "Bh6SevJQMFCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cuantos arboles necesitas en el bosque (200)\n",
        "rfc = RandomForestClassifier(n_estimators=200)\n",
        "rfc.fit(X_train, y_train)\n",
        "pred_rfc = rfc.predict(X_test)"
      ],
      "metadata": {
        "id": "1homhUQCMIMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_rfc[:20]"
      ],
      "metadata": {
        "id": "iQP3OJ2FMMLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[:20]"
      ],
      "metadata": {
        "id": "MtvxVhjnMPe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's see how our model performed\n",
        "print(classification_report(y_test, pred_rfc))"
      ],
      "metadata": {
        "id": "_InC6rxqMSkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix for the random forest classification\n",
        "#Vemos que el modelo es bueno prediciendo vino malo (263,10) pero el modelo es\n",
        "#malo prediciendo vino bueno (32, 15)\n",
        "print(confusion_matrix(y_test, pred_rfc))"
      ],
      "metadata": {
        "id": "CtveF-24MVTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "cm = accuracy_score(y_test, pred_rfc)\n",
        "\n",
        "cm"
      ],
      "metadata": {
        "id": "xBWQhbmtMXkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head(10)"
      ],
      "metadata": {
        "id": "wipStiHZMcoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CHECKING FOR A SAMPLE\n",
        "Xnew = [[7.4,0.70,0.00,1.9,0.076,11.0,34.0,0.9978,3.51,0.56,9.4]]\n",
        "ynew = rfc.predict(Xnew)"
      ],
      "metadata": {
        "id": "IUGF3pSfMfHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The quality of wine with given parameters is:')\n",
        "print(ynew)"
      ],
      "metadata": {
        "id": "9OeL_KzfMjFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hGcYhNc8Mqjb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.- SVM CLASSIFIER"
      ],
      "metadata": {
        "id": "82-QZeTwM4Y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf=svm.SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "pred_clf=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "d1UtTbZhM6_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred_clf))\n",
        "print(confusion_matrix(y_test, pred_clf))"
      ],
      "metadata": {
        "id": "uizBuv-wM_UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.- NEURAL NETWORK"
      ],
      "metadata": {
        "id": "KtWZ4GtyNEA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlpc=MLPClassifier(hidden_layer_sizes=(11, 11, 11), max_iter=500)\n",
        "mlpc.fit(X_train, y_train)\n",
        "pred_mlpc=mlpc.predict(X_test)"
      ],
      "metadata": {
        "id": "oB1vQrVINIBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred_mlpc))\n",
        "print(confusion_matrix(y_test, pred_mlpc))"
      ],
      "metadata": {
        "id": "lSaajDk0NLIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "cm=accuracy_score(y_test, pred_rfc)\n",
        "cm"
      ],
      "metadata": {
        "id": "BbteQjxsNOS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine.head(10)"
      ],
      "metadata": {
        "id": "jmmOSx0INSf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xnew= [[7.3, 0.58, 0.00, 2.0, 0.065, 15.0, 21.0, 0.9946, 3.36, 0.47, 10.0]]\n",
        "Xnew= sc.transform(Xnew)\n",
        "ynew=rfc.predict(Xnew)\n",
        "ynew"
      ],
      "metadata": {
        "id": "hL-XYCPfNT0h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}