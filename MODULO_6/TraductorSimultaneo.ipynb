{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PM_Mxo3WXGKq7TUMU5H-HjauFNIg5xr7","timestamp":1701684055383}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Para este ejercicio, utilizaremos la biblioteca transformers de Hugging Face, que proporciona acceso a modelos de traducción preentrenados como el modelo Helsinki-NLP para traducción automática. Primero, deberás instalar la biblioteca transformers y sentencepiece que se necesita para el procesamiento del texto."],"metadata":{"id":"03s3ulyT8y6D"}},{"cell_type":"markdown","source":["Un \"transformer\" en el campo del procesamiento del lenguaje natural (NLP) es un tipo de modelo que se utiliza para comprender y generar lenguaje humano de manera efectiva. La forma más sencilla de entenderlo es compararlo con cómo aprendemos los idiomas: al escuchar o leer, no solo prestamos atención a una palabra a la vez, sino que consideramos el contexto completo para entender el significado. Los transformers hacen algo similar pero de manera computacional.\n","Aquí está cómo funcionan los transformers, simplificado:\n","\n","\n","1.   ***Atención***: La característica clave de un transformer es su capacidad de \"atención\". Esto significa que el modelo puede enfocarse en diferentes partes de una oración para entender mejor su significado completo. Por ejemplo, en la frase \"El gato, que estaba cansado, dormía en el sofá\", el modelo reconoce que \"el gato\" está relacionado con \"dormía\".\n","2.   ***Procesamiento en paralelo***: A diferencia de los modelos anteriores que procesaban las palabras una por una en secuencia, los transformers pueden procesar todas las palabras de una oración al mismo tiempo. Esto los hace más rápidos y eficientes.\n","3.   ***Codificadores y Decodificadores***: Los transformers suelen tener dos partes principales: codificadores y decodificadores. Los codificadores se encargan de comprender el texto de entrada, mientras que los decodificadores generan el texto de salida. Por ejemplo, en la traducción automática, el codificador analiza la oración en inglés y el decodificador genera la traducción en español.\n","4.   ***Capas de Redes Neuronales***: Los transformers están compuestos por muchas capas de redes neuronales. Estas capas ayudan al modelo a aprender aspectos complejos del lenguaje, como la gramática, el tono y el contexto.\n","\n","En resumen, los transformers son como lectores inteligentes y escritores automáticos que pueden comprender y producir lenguaje considerando el contexto completo de las palabras, no solo una palabra a la vez. Su habilidad para procesar todo el texto simultáneamente y su sistema de atención los hacen muy efectivos para tareas como la traducción automática, la generación de texto, y la comprensión del lenguaje natural."],"metadata":{"id":"ob0gQZRaIPtA"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCYPuDbp8eQO"},"outputs":[],"source":["pip install transformers sentencepiece"]},{"cell_type":"markdown","source":["La biblioteca **SentencePiece** es una herramienta utilizada en el procesamiento del lenguaje natural (NLP) que facilita una parte importante del preprocesamiento del texto: la tokenización. En el contexto de NLP, ***tokenizar significa dividir el texto en piezas más pequeñas***, llamadas tokens.\n","\n","En resumen, **SentencePiece** es una herramienta de tokenización avanzada que ayuda a los modelos de NLP a manejar una variedad de desafíos del lenguaje, como la tokenización en idiomas sin espacios, el manejo de palabras raras y el procesamiento multilingüe. Su capacidad para crear tokenizadores personalizados y su eficacia en la tokenización de subpalabras lo hacen una opción popular en el campo del NLP."],"metadata":{"id":"ldH3t_gkJmJo"}},{"cell_type":"markdown","source":["Este código usa un modelo preentrenado de Hugging Face para traducir texto del inglés al español. La función simple_translator recibe una entrada de texto del usuario, la procesa con el tokenizer del modelo y luego genera la traducción utilizando el modelo."],"metadata":{"id":"R_8rh0Qm9ReU"}},{"cell_type":"code","source":["from transformers import MarianMTModel, MarianTokenizer"],"metadata":{"id":"8X-_OuQv9D_3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aquí se importan dos clases del módulo transformers: **MarianMTModel** y **MarianTokenizer**.\n","**MarianMTModel** es un modelo de traducción automática basado en redes neuronales, mientras que **MarianTokenizer** se encarga del procesamiento del texto (tokenización)."],"metadata":{"id":"NK3tCi1oKMx9"}},{"cell_type":"code","source":["def simple_translator():\n","    # Seleccionar el modelo de traducción. Aquí usamos un modelo para traducir del inglés al español.\n","    model_name = 'Helsinki-NLP/opus-mt-en-es'\n","    model = MarianMTModel.from_pretrained(model_name)\n","    tokenizer = MarianTokenizer.from_pretrained(model_name)\n","\n","    while True:\n","        # Recibir texto en inglés del usuario\n","        text = input(\"Ingresa el texto en inglés a traducir (o 'salir' para terminar): \")\n","        if text.lower() == 'salir':\n","            break\n","\n","        # Preprocesar y traducir el texto\n","        translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))\n","\n","        # Mostrar el texto traducido\n","        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n","        print(f\"Traducción al español: {translated_text}\\n\")"],"metadata":{"id":"ipK2dy2SKCbp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A continuación se detalla la lógica de la función <code>simple_translator</code> que hemos definido:\n","\n","\n","\n","*   **Definición de la función**:  \n","<code>simple_translator()</code>:  \n","Esta función contiene toda la lógica para el traductor.  \n","\n","*   **Selección del modelo de traducción**:  \n","<code>model_name = 'Helsinki-NLP/opus-mt-en-es'</code>  \n","Se especifica el nombre del modelo de traducción que se va a utilizar. En este caso, se usa el modelo 'Helsinki-NLP/opus-mt-en-es', que está diseñado para traducir del inglés al español.\n","*   **Cargar el modelo y el tokenizador**:  \n","<code>model = MarianMTModel.from_pretrained(model_name)</code>  \n","<code>tokenizer = MarianTokenizer.from_pretrained(model_name)</code>  \n","Se cargan el modelo y el tokenizador utilizando el nombre del modelo. from_pretrained es un método que carga un modelo preentrenado desde un repositorio en línea.\n","*   **Bucle infinito para recibir texto del usuario**:  \n","<code>while True:</code>  \n","Un bucle while True se utiliza para recibir continuamente texto del usuario hasta que decida salir.\n","*   **Recibir texto en inglés del usuario**:  \n","<code>text = input(\"Ingresa el texto en inglés a traducir (o 'salir' para terminar): \")</code>  \n","Se solicita al usuario que ingrese el texto en inglés que desea traducir. Si el usuario escribe 'salir', el programa se detiene.\n","*   **Condición para salir del bucle**:  \n","<code>if text.lower() == 'salir':</code>  \n","<code>break</code>  \n","  Si el usuario escribe 'salir', se convierte a minúsculas para asegurar que coincida sin importar cómo se escriba, y se usa break para salir del bucle.\n","*   **Preprocesar y traducir el texto**:  \n","<code>translated = model.generate(**tokenizer(text, return_tensors=\"pt\", padding=True))</code>  \n","El texto ingresado se procesa primero con el tokenizador y luego se pasa al modelo para generar la traducción. <code>return_tensors=\"pt\"</code> indica que se devolverán tensores de PyTorch, y <code>padding=True</code> agrega relleno si es necesario.\n","*   **Mostrar el texto traducido**:  \n","<code>translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)</code>  \n","<code>print(f\"Traducción al español: {translated_text}\\n\")</code>  \n","Se decodifica el resultado de la traducción para convertirlo de nuevo a texto y se imprime la traducción.\n","\n"],"metadata":{"id":"xGKmLrzyKs1K"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    simple_translator()"],"metadata":{"id":"Ugeui-WCK4CX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*   Ejecución principal:  \n","<code>if __name__ == \"__main__\":</code>  \n","<code>simple_translator()</code>  \n","Este bloque asegura que simple_translator() solo se ejecute si el script se está ejecutando como programa principal y no cuando se importa como un módulo en otro script."],"metadata":{"id":"IhUjX8Q0QVgk"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"URmJIcM1RdH-"},"execution_count":null,"outputs":[]}]}